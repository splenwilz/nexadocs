"""add_document_chunks_table

Revision ID: 62b64a023e16
Revises: 869f5615c3ec
Create Date: 2025-11-28 04:24:45.571417

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '62b64a023e16'
down_revision: Union[str, Sequence[str], None] = '869f5615c3ec'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('tasks',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(length=200), nullable=False),
    sa.Column('description', sa.String(length=1000), nullable=True),
    sa.Column('completed', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tasks_id'), 'tasks', ['id'], unique=False)
    op.create_index(op.f('ix_tasks_title'), 'tasks', ['title'], unique=False)
    op.create_table('document_chunks',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('document_id', sa.UUID(), nullable=False),
    sa.Column('tenant_id', sa.UUID(), nullable=False),
    sa.Column('chunk_index', sa.Integer(), nullable=False, comment='Position of chunk within document (0-based)'),
    sa.Column('page_number', sa.Integer(), nullable=False, comment='Page number in original PDF (1-based, for citations)'),
    sa.Column('text', sa.Text(), nullable=False),
    sa.Column('embedding', postgresql.ARRAY(sa.Float()), nullable=True, comment='Vector embedding (null if using external vector DB)'),
    sa.Column('token_count', sa.Integer(), nullable=True, comment='Approximate number of tokens in chunk'),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['tenant_id'], ['tenants.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_document_chunks_chunk_index'), 'document_chunks', ['chunk_index'], unique=False)
    op.create_index(op.f('ix_document_chunks_created_at'), 'document_chunks', ['created_at'], unique=False)
    op.create_index(op.f('ix_document_chunks_document_id'), 'document_chunks', ['document_id'], unique=False)
    op.create_index(op.f('ix_document_chunks_id'), 'document_chunks', ['id'], unique=False)
    op.create_index(op.f('ix_document_chunks_page_number'), 'document_chunks', ['page_number'], unique=False)
    op.create_index(op.f('ix_document_chunks_tenant_id'), 'document_chunks', ['tenant_id'], unique=False)
    op.alter_column('documents', 'file_size',
               existing_type=sa.INTEGER(),
               comment='File size in bytes',
               existing_nullable=False)
    op.alter_column('documents', 'status',
               existing_type=sa.VARCHAR(length=20),
               type_=sa.Enum('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', name='documentstatus', native_enum=False),
               existing_nullable=False,
               existing_server_default=sa.text("'pending'::character varying"))
    op.alter_column('documents', 'page_count',
               existing_type=sa.INTEGER(),
               comment='Number of pages extracted from PDF',
               existing_nullable=True)
    op.alter_column('documents', 'chunk_count',
               existing_type=sa.INTEGER(),
               comment='Number of text chunks created for embeddings',
               existing_nullable=True)
    op.drop_constraint(op.f('documents_file_path_key'), 'documents', type_='unique')
    op.alter_column('messages', 'role',
               existing_type=sa.VARCHAR(length=20),
               comment="Message role: 'user' or 'assistant'",
               existing_nullable=False)
    op.alter_column('messages', 'citations',
               existing_type=sa.TEXT(),
               comment='JSON string of document citations (for assistant messages only)',
               existing_nullable=True)
    op.alter_column('users', 'tenant_id',
               existing_type=sa.UUID(),
               nullable=False)
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=False)
    op.alter_column('validated_answers', 'admin_notes',
               existing_type=sa.TEXT(),
               comment='Optional notes explaining the correction',
               existing_nullable=True)
    op.drop_constraint(op.f('validated_answers_message_id_key'), 'validated_answers', type_='unique')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_unique_constraint(op.f('validated_answers_message_id_key'), 'validated_answers', ['message_id'], postgresql_nulls_not_distinct=False)
    op.alter_column('validated_answers', 'admin_notes',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Optional notes explaining the correction',
               existing_nullable=True)
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.alter_column('users', 'tenant_id',
               existing_type=sa.UUID(),
               nullable=True)
    op.alter_column('messages', 'citations',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='JSON string of document citations (for assistant messages only)',
               existing_nullable=True)
    op.alter_column('messages', 'role',
               existing_type=sa.VARCHAR(length=20),
               comment=None,
               existing_comment="Message role: 'user' or 'assistant'",
               existing_nullable=False)
    op.create_unique_constraint(op.f('documents_file_path_key'), 'documents', ['file_path'], postgresql_nulls_not_distinct=False)
    op.alter_column('documents', 'chunk_count',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of text chunks created for embeddings',
               existing_nullable=True)
    op.alter_column('documents', 'page_count',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of pages extracted from PDF',
               existing_nullable=True)
    op.alter_column('documents', 'status',
               existing_type=sa.Enum('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', name='documentstatus', native_enum=False),
               type_=sa.VARCHAR(length=20),
               existing_nullable=False,
               existing_server_default=sa.text("'pending'::character varying"))
    op.alter_column('documents', 'file_size',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='File size in bytes',
               existing_nullable=False)
    op.drop_index(op.f('ix_document_chunks_tenant_id'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_page_number'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_id'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_document_id'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_created_at'), table_name='document_chunks')
    op.drop_index(op.f('ix_document_chunks_chunk_index'), table_name='document_chunks')
    op.drop_table('document_chunks')
    op.drop_index(op.f('ix_tasks_title'), table_name='tasks')
    op.drop_index(op.f('ix_tasks_id'), table_name='tasks')
    op.drop_table('tasks')
    # ### end Alembic commands ###
